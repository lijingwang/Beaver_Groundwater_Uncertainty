{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8513aca-8006-4988-80a0-651b36df7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.linalg import norm\n",
    "import flopy\n",
    "import flopy.utils.binaryfile as bf\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import maximum_filter\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a975a1-d023-4e2f-adf4-556de120788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from Slate_Floodplain_MODFLOW import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7692b6-796f-444d-84d3-ba1eea72d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 480\n",
    "nrow = 460\n",
    "\n",
    "nlay = 16\n",
    "soil_nlay = 10\n",
    "gravel_nlay = nlay - soil_nlay\n",
    "dam_nlay = 5\n",
    "\n",
    "# setting up the vertical discretization and model bottom elevation\n",
    "zbot = np.zeros((nlay,nrow,ncol))\n",
    "\n",
    "# Soil layers\n",
    "for lay in np.arange(0,soil_nlay):    \n",
    "    zbot[lay,:,:] = DEM - np.maximum(gravel_interface*((lay+1)/soil_nlay),0.1*(lay+1)) \n",
    "\n",
    "# Gravel layers\n",
    "gravel_discretized_ratio = [0.02,0.04,0.1,0.3,0.6,1]\n",
    "for i, lay in enumerate(np.arange(soil_nlay, nlay)):\n",
    "    zbot[lay,:,:] = zbot[soil_nlay-1,:,:] - np.maximum(bedrock_interface*gravel_discretized_ratio[i],0.1*(i+1))\n",
    "    \n",
    "thickness = np.zeros(zbot.shape)\n",
    "for i in range(nlay):\n",
    "    if i == 0:\n",
    "        thickness[i,:,:] = DEM-zbot[i,:,:]\n",
    "    else:\n",
    "        thickness[i,:,:] = zbot[i-1,:,:]-zbot[i,:,:]\n",
    "depth_to_surface = DEM-zbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517fca6-3f50-4d07-8448-39ca3925ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values \n",
    "hk_gravel = 2e-3 #m/s\n",
    "hk_soil = 1.4e-5 #m/s\n",
    "vka_ratio_gravel = 0.5 #m/s\n",
    "vka_ratio_soil = 0.1 #m/s\n",
    "k_dam = 1e-7 #m/s\n",
    "\n",
    "precip = 2e-3 #m/d\n",
    "ET = 2e-3 #m/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0924d1-143b-4300-a695-d0f1d967e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf,head,hk,vka,strt,zbot,flf,frf = modflow_BC(hk_gravel,hk_soil,vka_ratio_gravel,vka_ratio_soil,k_dam,\n",
    "                                              ET,precip-ET, 'test', './baseflow_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6704a7-fb37-43bf-baa3-75b189610c34",
   "metadata": {},
   "source": [
    "# Local and Regional Groundwater Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81931b5-3151-44c2-8a4b-d047633389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream = np.load('../data/characterization_data/Beaver_pond_dam/floodplain_downstream.npy')\n",
    "upstream = np.load('../data/characterization_data/Beaver_pond_dam/floodplain_upstream.npy')\n",
    "downstream[:,300:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1ed25-afc1-4e4d-b55d-af68f84ac442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downward flow on top of gravel bed (river)\n",
    "def dw_river(flf):\n",
    "    spatial_mask = (river+pond-dam ==2)\n",
    "    velocity = flf[soil_nlay-1,:,:]*spatial_mask\n",
    "    return velocity\n",
    "\n",
    "# Downward flow on top of soil layer (floodplain)\n",
    "def dw_floodplain(flf):\n",
    "    spatial_mask = (upstream+downstream==1)\n",
    "    velocity = flf[soil_nlay-1,:,:]*spatial_mask\n",
    "    return velocity\n",
    "\n",
    "# Horizontal flow though dam cross section (river)\n",
    "def h_dam_river(frf,dam_section = 240):\n",
    "    velocity = (frf/thickness)[:,:,dam_section]\n",
    "    line_mask = np.zeros(frf.shape[1])\n",
    "    line_mask[np.where((river+pond-dam ==2))[0].min():(np.where((river+pond-dam ==2))[0].max()+2)] = 1\n",
    "    spatial_mask = line_mask[np.newaxis, :]==1\n",
    "    velocity = velocity*spatial_mask\n",
    "    return velocity\n",
    "\n",
    "# Horizontal flow though dam cross section (floodplain)\n",
    "def h_dam_floodplain(frf,dam_section = 240):\n",
    "    velocity = (frf/thickness)[:,:,dam_section]\n",
    "    spatial_mask = (upstream+downstream)[:,dam_section][np.newaxis, :]==1\n",
    "    velocity = velocity*spatial_mask\n",
    "    return velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea169c-5c34-4747-a8f8-9342f5e5c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_regional_response(flf,frf):\n",
    "    dam_section = 240\n",
    "    dw_r = dw_river(flf)\n",
    "    dw_f = dw_floodplain(flf)\n",
    "    h_v_r = h_dam_river(frf)\n",
    "    h_v_f = h_dam_floodplain(frf)\n",
    "    h_flux_r = h_v_r*thickness[:,:,dam_section]\n",
    "    h_flux_f = h_v_f*thickness[:,:,dam_section]\n",
    "    return dw_r,dw_f,h_v_r,h_v_f,h_flux_r,h_flux_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e0e47-03b1-4ae4-9c04-caea82f1d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcings = pd.read_csv('../data/response_data/preprocessing/period_forcings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c02e2e-0417-47f6-86f6-a468253dc223",
   "metadata": {},
   "source": [
    "# Result for Set 2, calibrated baseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579b1c1-683d-477d-af87-b449cabc3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_MC = 300\n",
    "\n",
    "all_dw_r = np.zeros((num_MC, nrow,ncol))\n",
    "all_dw_f = np.zeros((num_MC, nrow,ncol))\n",
    "all_h_v_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_v_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_head = np.zeros((num_MC,nlay, nrow,ncol))\n",
    "\n",
    "for i in tqdm(range(num_MC)):\n",
    "    head,flf,frf = read_sim('./Posterior_Simulation/sim'+str(i).zfill(3),'sim'+str(i).zfill(3))\n",
    "    all_head[i,:]  = head\n",
    "    # Calculate responses for current case\n",
    "    dw_r_i, dw_f_i, h_v_r_i, h_v_f_i, h_flux_r_i, h_flux_f_i = local_regional_response(flf, frf)\n",
    "\n",
    "    # Store results in arrays\n",
    "    all_dw_r[i, :] = dw_r_i\n",
    "    all_dw_f[i, :] = dw_f_i\n",
    "    all_h_v_r[i] = h_v_r_i\n",
    "    all_h_v_f[i] = h_v_f_i\n",
    "    all_h_flux_r[i, :] = h_flux_r_i\n",
    "    all_h_flux_f[i, :] = h_flux_f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee851ab-6985-426a-a2a1-2c2d80afc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'all_head' is your data array\n",
    "data = np.mean(all_head, axis=0)[5, :, :]\n",
    "data[data<0] = np.nan\n",
    "# Plot the image\n",
    "plt.imshow(data, cmap='magma', vmin=2724, vmax=2726)\n",
    "\n",
    "# Add contour lines\n",
    "contour_levels = np.linspace(2724, 2726, 10)  # Adjust the number of contour levels as needed\n",
    "plt.contour(data, levels=contour_levels, colors='grey')\n",
    "\n",
    "plt.axis('off')\n",
    "#plt.colorbar()  # Add colorbar for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37c88e-af68-45da-a5bb-6c7b43d25f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = 60*60*24\n",
    "all_dw_r_sum = np.sum((all_dw_r*(all_dw_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_dw_f_sum = np.sum((all_dw_f*(all_dw_f>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_r_sum = np.sum((all_h_flux_r*(all_h_flux_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_f_sum = np.sum((all_h_flux_f*(all_h_flux_f>0)).reshape(num_MC,-1),axis = 1)/spd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801ec6b-9c50-4930-9854-14ed4745f97d",
   "metadata": {},
   "source": [
    "# Result for Set 2, snowmelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698cd505-480a-4e90-8425-4cf38c10f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_MC = 300\n",
    "\n",
    "all_dw_r = np.zeros((num_MC, nrow,ncol))\n",
    "all_dw_f = np.zeros((num_MC, nrow,ncol))\n",
    "all_h_v_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_v_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_f = np.zeros((num_MC,nlay, nrow))\n",
    "\n",
    "for i in tqdm(range(num_MC)):\n",
    "    head,flf,frf = read_sim('./Posterior_Simulation_Snowmelt/sim'+str(i).zfill(3),'sim'+str(i).zfill(3))\n",
    "\n",
    "    # Calculate responses for current case\n",
    "    dw_r_i, dw_f_i, h_v_r_i, h_v_f_i, h_flux_r_i, h_flux_f_i = local_regional_response(flf, frf)\n",
    "\n",
    "    # Store results in arrays\n",
    "    all_dw_r[i, :] = dw_r_i\n",
    "    all_dw_f[i, :] = dw_f_i\n",
    "    all_h_v_r[i] = h_v_r_i\n",
    "    all_h_v_f[i] = h_v_f_i\n",
    "    all_h_flux_r[i, :] = h_flux_r_i\n",
    "    all_h_flux_f[i, :] = h_flux_f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54dc29-0f09-4e79-8226-8e1fa5f39923",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = 60*60*24\n",
    "all_dw_r_sum = np.sum((all_dw_r*(all_dw_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_dw_f_sum = np.sum((all_dw_f*(all_dw_f>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_r_sum = np.sum((all_h_flux_r*(all_h_flux_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_f_sum = np.sum((all_h_flux_f*(all_h_flux_f>0)).reshape(num_MC,-1),axis = 1)/spd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165a6a1-add9-4fe3-a462-a3181238f3c2",
   "metadata": {},
   "source": [
    "# Result for Set 2, dry pond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ac579-9dd3-437f-a096-579542dde1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_MC = 300\n",
    "\n",
    "all_dw_r = np.zeros((num_MC, nrow,ncol))\n",
    "all_dw_f = np.zeros((num_MC, nrow,ncol))\n",
    "all_h_v_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_v_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_f = np.zeros((num_MC,nlay, nrow))\n",
    "\n",
    "for i in tqdm(range(num_MC)):\n",
    "    head,flf,frf = read_sim('./Posterior_Simulation_Drypond/sim'+str(i).zfill(3),'sim'+str(i).zfill(3))\n",
    "\n",
    "    # Calculate responses for current case\n",
    "    dw_r_i, dw_f_i, h_v_r_i, h_v_f_i, h_flux_r_i, h_flux_f_i = local_regional_response(flf, frf)\n",
    "\n",
    "    # Store results in arrays\n",
    "    all_dw_r[i, :] = dw_r_i\n",
    "    all_dw_f[i, :] = dw_f_i\n",
    "    all_h_v_r[i] = h_v_r_i\n",
    "    all_h_v_f[i] = h_v_f_i\n",
    "    all_h_flux_r[i, :] = h_flux_r_i\n",
    "    all_h_flux_f[i, :] = h_flux_f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9500251-a749-4839-93f1-a8aebea56804",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = 60*60*24\n",
    "all_dw_r_sum = np.sum((all_dw_r*(all_dw_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_dw_f_sum = np.sum((all_dw_f*(all_dw_f>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_r_sum = np.sum((all_h_flux_r*(all_h_flux_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_f_sum = np.sum((all_h_flux_f*(all_h_flux_f>0)).reshape(num_MC,-1),axis = 1)/spd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f8036-e260-46c6-82f5-d2f6890299f6",
   "metadata": {},
   "source": [
    "# Result for varying: structure, ET, precip, ponding period, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294304e2-7f98-4123-a63e-18ceb4441344",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.read_csv('./Simulation_More_Variations/Parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7707261-5467-4a10-8824-6de986a2b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['period'] = pd.factorize(parameters['period'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d8122-8630-45cc-b45c-51a641458d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_paras = parameters[parameters.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db658f8-10b0-4c9c-a8c6-f22bdff357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_paras[log_paras.columns[:5]] = np.log10(log_paras[log_paras.columns[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4820a-254f-4538-88cc-0bcbca1095fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thickness_from_ratio(structure_ratio1,structure_ratio2):\n",
    "    # setting up the vertical discretization and model bottom elevation\n",
    "    zbot = np.zeros((nlay,nrow,ncol))\n",
    "    \n",
    "    # Soil layers\n",
    "    for lay in np.arange(0,soil_nlay):    \n",
    "        zbot[lay,:,:] = DEM - np.maximum(gravel_interface*structure_ratio1*((lay+1)/soil_nlay),0.1*(lay+1)) \n",
    "    \n",
    "    # Gravel layers\n",
    "    gravel_discretized_ratio = [0.02,0.04,0.1,0.3,0.6,1]\n",
    "    for i, lay in enumerate(np.arange(soil_nlay, nlay)):\n",
    "        zbot[lay,:,:] = zbot[soil_nlay-1,:,:] - np.maximum(bedrock_interface*structure_ratio2*gravel_discretized_ratio[i],0.1*(i+1))\n",
    "\n",
    "    thickness = np.zeros(zbot.shape)\n",
    "    for i in range(nlay):\n",
    "        if i == 0:\n",
    "            thickness[i,:,:] = DEM-zbot[i,:,:]\n",
    "        else:\n",
    "            thickness[i,:,:] = zbot[i-1,:,:]-zbot[i,:,:]\n",
    "    return thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a6465-0ccc-4868-8461-ff23a92bbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_regional_response_structure_change(flf,frf, structure_ratio1,structure_ratio2):\n",
    "    thickness = thickness_from_ratio(structure_ratio1,structure_ratio2)\n",
    "    dam_section = 240\n",
    "    dw_r = dw_river(flf)\n",
    "    dw_f = dw_floodplain(flf)\n",
    "    h_v_r = h_dam_river(frf)\n",
    "    h_v_f = h_dam_floodplain(frf)\n",
    "    h_flux_r = h_v_r*thickness[:,:,dam_section]\n",
    "    h_flux_f = h_v_f*thickness[:,:,dam_section]\n",
    "    return dw_r,dw_f,h_v_r,h_v_f,h_flux_r,h_flux_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc6b9e-37ed-4fd6-9f87-760607746dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_MC = 500\n",
    "\n",
    "all_dw_r = np.zeros((num_MC, nrow,ncol))\n",
    "all_dw_f = np.zeros((num_MC, nrow,ncol))\n",
    "all_h_v_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_v_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_r = np.zeros((num_MC,nlay, nrow))\n",
    "all_h_flux_f = np.zeros((num_MC,nlay, nrow))\n",
    "all_head = np.zeros((num_MC,nlay, nrow,ncol))\n",
    "\n",
    "for i in tqdm(range(num_MC)):\n",
    "    if parameters['success'][i]==1:\n",
    "        structure_ratio1 = parameters['structure_ratio1'][i]\n",
    "        structure_ratio2 = parameters['structure_ratio2'][i]\n",
    "        head,flf,frf = read_sim('./Simulation_More_Variations/sim'+str(i).zfill(3),'sim'+str(i).zfill(3))\n",
    "        all_head[i,:]  = head\n",
    "        # Calculate responses for current case\n",
    "        dw_r_i, dw_f_i, h_v_r_i, h_v_f_i, h_flux_r_i, h_flux_f_i = local_regional_response_structure_change(flf, frf,structure_ratio1,structure_ratio2)\n",
    "\n",
    "        # Store results in arrays\n",
    "        all_dw_r[i, :] = dw_r_i\n",
    "        all_dw_f[i, :] = dw_f_i\n",
    "        all_h_v_r[i] = h_v_r_i\n",
    "        all_h_v_f[i] = h_v_f_i\n",
    "        all_h_flux_r[i, :] = h_flux_r_i\n",
    "        all_h_flux_f[i, :] = h_flux_f_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5edba9-ca32-48b6-ac2f-600a733154bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = 60*60*24 \n",
    "all_dw_r_sum = np.sum((all_dw_r*(all_dw_r>0)).reshape(num_MC,-1),axis = 1)/spd #(m3/s)\n",
    "all_dw_f_sum = np.sum((all_dw_f*(all_dw_f>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_r_sum = np.sum((all_h_flux_r*(all_h_flux_r>0)).reshape(num_MC,-1),axis = 1)/spd\n",
    "all_h_flux_f_sum = np.sum((all_h_flux_f*(all_h_flux_f>0)).reshape(num_MC,-1),axis = 1)/spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7e96c-dd38-4bcd-b440-bef3443af387",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_all = pd.DataFrame(np.array([all_dw_r_sum,all_dw_f_sum,\n",
    "                                  all_h_flux_r_sum,\n",
    "                                  all_h_flux_f_sum]).T)\n",
    "\n",
    "# Define new column names\n",
    "new_columns = ['$Q_z^r$', '$Q_z^f$', '$Q_x^r$', '$Q_x^f$']\n",
    "\n",
    "# Rename columns\n",
    "flux_all.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5496e66-8075-464c-b041-d48fd473433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_paras['period'] = pd.factorize(log_paras['period'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ec8ea-d125-4f7b-a0ee-7a097bc8a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "new_path = '../scripts/DGSA_Light/'\n",
    "\n",
    "sys.path.append(new_path)\n",
    "\n",
    "from DGSA_light import DGSA_light\n",
    "from gsa_pareto_plt import gsa_pareto_plt\n",
    "def colors_from_values(values, palette_name):\n",
    "    # normalize the values to range [0, 1]\n",
    "    normalized = (values - 0) / (1 - 0)\n",
    "    # convert to indices\n",
    "    indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f2e69-ae66-4b24-af21-ed23d6368f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = ['log $K_{h}^{gravel}$','log $K_{h}^{soil}$',\n",
    "          'log($K_{v}^{gravel}/K_{h}^{gravel}$)',\n",
    "          'log($K_{v}^{soil}/K_{h}^{soil}$)','log $K^{dam}$',\n",
    "          'ET', 'Precipitation','Periods','Soil thickness','Gravel thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82837f96-7ea0-4664-99da-78d4838c6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = '$Q_z^f$'\n",
    "dgsa_measures = DGSA_light(log_paras.values[parameters['success']==1,:], flux_all[variable].values.reshape(-1,1)[parameters['success']==1],\n",
    "                           xlabel)\n",
    "\n",
    "dgsa_measures['name'] = xlabel\n",
    "dgsa_measures['sensitive'] = (dgsa_measures[0]>1)*1\n",
    "\n",
    "dgsa_measures = dgsa_measures.sort_values(by=dgsa_measures.columns[0],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba7f42-14da-4bca-9e84-d918aa2e62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 3)) \n",
    "sns.barplot(x = 0,y = 'name', data=dgsa_measures,palette = colors_from_values(dgsa_measures['sensitive'], \"RdBu_r\"))\n",
    "plt.vlines(x = 1, ymin = -1, ymax = len(log_paras.columns),color = 'black',linestyle = '--')\n",
    "plt.xlabel('Sensitivity measurement')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0,5)\n",
    "plt.title(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e0c48-5feb-4936-a786-3b9c8dfdacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = '$Q_z^f$'\n",
    "dgsa_measures = DGSA_light(log_paras.values[parameters['success']==1,:], \n",
    "                           flux_all[variable].values.reshape(-1,1)[parameters['success']==1]/flux_all['$Q_x^f$'].values.reshape(-1,1)[parameters['success']==1],\n",
    "                           xlabel)\n",
    "\n",
    "dgsa_measures['name'] = xlabel\n",
    "dgsa_measures['sensitive'] = (dgsa_measures[0]>1)*1\n",
    "\n",
    "dgsa_measures = dgsa_measures.sort_values(by=dgsa_measures.columns[0],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bfefc-0009-4932-b3de-73fea326fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 3)) \n",
    "sns.barplot(x = 0,y = 'name', data=dgsa_measures,palette = colors_from_values(dgsa_measures['sensitive'], \"RdBu_r\"))\n",
    "plt.vlines(x = 1, ymin = -1, ymax = len(log_paras.columns),color = 'black',linestyle = '--')\n",
    "plt.xlabel('Sensitivity measurement')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0,5)\n",
    "plt.title(variable+'/$Q_x^f$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110cbeb-ea67-4084-b4e3-0f395db7210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_paras = log_paras.drop(columns=['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daba117-4f47-4930-8d81-b3c51324fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = ['log $K_{h}^{gravel}$','log $K_{h}^{soil}$',\n",
    "          'log($K_{v}^{gravel}/K_{h}^{gravel}$)',\n",
    "          'log($K_{v}^{soil}/K_{h}^{soil}$)','log $K^{dam}$',\n",
    "          'ET', 'Precipitation','Soil thickness','Gravel thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03098194-c661-44d2-ad8d-7504f6dfe052",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_m_s = all_dw_f/spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc8aeb-a0e9-47ac-b13a-4246f4e54997",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -4\n",
    "plt.figure(figsize=[5,5])\n",
    "pond_vis = np.array(np.copy(pond),dtype = 'float64')\n",
    "pond_vis[pond_vis ==0] = np.nan\n",
    "SA_matrix_vis = SA_matrix[i,:,:]\n",
    "SA_matrix_vis[SA_matrix_vis<1] = np.nan\n",
    "plt.imshow(SA_matrix_vis,vmin = 1,vmax = 3.8,cmap = 'PuRd')\n",
    "plt.colorbar(shrink = 0.3)\n",
    "plt.imshow(pond_vis,cmap = 'Blues_r',alpha = 0.1)\n",
    "plt.axis('off')\n",
    "plt.title(xlabel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679d555-b9c8-4865-aaa3-389c2cadbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=[5,5])\n",
    "pond_vis = np.array(np.copy(pond),dtype = 'float64')\n",
    "pond_vis[pond_vis ==0] = np.nan\n",
    "SA_matrix_vis = SA_matrix[i,:,:]\n",
    "SA_matrix_vis[SA_matrix_vis<1] = np.nan\n",
    "plt.imshow(SA_matrix_vis,vmin = 1,vmax = 3.8,cmap = 'PuRd')\n",
    "plt.colorbar(shrink = 0.3)\n",
    "plt.imshow(pond_vis,cmap = 'Blues_r',alpha = 0.1)\n",
    "plt.axis('off')\n",
    "plt.title(xlabel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106cd69-d6e7-45f2-bb4b-d25b4a2bc037",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.figure(figsize=[5,5])\n",
    "pond_vis = np.array(np.copy(pond),dtype = 'float64')\n",
    "pond_vis[pond_vis ==0] = np.nan\n",
    "SA_matrix_vis = SA_matrix[i,:,:]\n",
    "SA_matrix_vis[SA_matrix_vis<1] = np.nan\n",
    "plt.imshow(SA_matrix_vis,vmin = 1,vmax = 3.8,cmap = 'PuRd')\n",
    "plt.colorbar(shrink = 0.3)\n",
    "plt.imshow(pond_vis,cmap = 'Blues_r',alpha = 0.1)\n",
    "plt.axis('off')\n",
    "plt.title(xlabel[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502613db-494e-4f6d-b441-7dfb32ffbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f100f01-6c31-42dc-bfdf-2b9480ba8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameters['structure_ratio1'],\n",
    "            all_dw_f_sum/all_h_flux_f_sum,c = np.log10(parameters['hk_soil']*parameters['vka_ratio_soil']/parameters['hk_gravel']))\n",
    "plt.colorbar()\n",
    "plt.yscale('log') \n",
    "#plt.xscale('log') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74f53b-f6ec-42ed-a082-00bb07ab825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gravel_interface = np.load('../model/subsurface/predict_gravel.npy')\n",
    "gravel_interface[np.isnan(gravel_interface)] = 0\n",
    "bedrock_interface = np.load('../model/subsurface/predict_bedrock.npy')\n",
    "bedrock_interface[np.isnan(bedrock_interface)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3b3d2-a3ac-4396-831f-72b46d53663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Assuming `parameters`, `all_dw_f_sum`, and `all_h_flux_f_sum` are already defined\n",
    "\n",
    "# Filter out period == 1\n",
    "filtered_parameters = parameters[parameters['period'] != 1]\n",
    "structure_ratio2 = filtered_parameters['structure_ratio2']\n",
    "hk_soil = filtered_parameters['hk_soil']\n",
    "vka_ratio_soil = filtered_parameters['vka_ratio_soil']\n",
    "hk_gravel = filtered_parameters['hk_gravel']\n",
    "\n",
    "# Calculate the color array\n",
    "color = np.log10(hk_soil * vka_ratio_soil )\n",
    "\n",
    "# Calculate the y values for the scatter plot\n",
    "y_values = (all_dw_f_sum / all_h_flux_f_sum)[parameters['period'] != 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(structure_ratio2, y_values,s = 20, c=color,vmin = -7.5,vmax = -4.5)\n",
    "plt.colorbar(label='$\\log(K_{v}^{soil})$')\n",
    "plt.xlim(0.01,3)\n",
    "plt.yscale('log') \n",
    "plt.xscale('log') \n",
    "plt.xlabel('Gravel Thickness (m)')\n",
    "plt.ylabel('$\\log(Q_z^f/Q_x^f)$')\n",
    "\n",
    "# Define the custom formatter function\n",
    "def custom_xaxis_formatter(x, pos):\n",
    "    if x == 0.1:\n",
    "        return '1.4'\n",
    "    elif x == 1:\n",
    "        return '14'\n",
    "    elif x == 0.01:\n",
    "        return '0.14'\n",
    "    else:\n",
    "        return f'{x}'\n",
    "\n",
    "# Apply the custom formatter to the x-axis\n",
    "formatter = FuncFormatter(custom_xaxis_formatter)\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b991b1f-5119-4909-8eef-4d65d287b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Assuming `parameters`, `all_dw_f_sum`, and `all_h_flux_f_sum` are already defined\n",
    "\n",
    "# Filter out period == 1\n",
    "filtered_parameters = parameters[parameters['period'] != 1]\n",
    "structure_ratio2 = filtered_parameters['structure_ratio2']\n",
    "hk_soil = filtered_parameters['hk_soil']\n",
    "vka_ratio_soil = filtered_parameters['vka_ratio_soil']\n",
    "hk_gravel = filtered_parameters['hk_gravel']\n",
    "\n",
    "# Calculate the color array\n",
    "color = np.log10(hk_soil * vka_ratio_soil / hk_gravel)\n",
    "\n",
    "# Calculate the y values for the scatter plot\n",
    "y_values = (all_dw_f_sum / all_h_flux_f_sum)[parameters['period'] != 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(structure_ratio2, y_values, c=color)\n",
    "plt.colorbar(label='$\\log(K_{v}^{soil}/K_{h}^{gravel})$')\n",
    "plt.xlim(0.01,3)\n",
    "plt.yscale('log') \n",
    "plt.xscale('log') \n",
    "plt.xlabel('Gravel Thickness (m)')\n",
    "plt.ylabel('$\\log(Q_z^f/Q_x^f)$')\n",
    "\n",
    "# Define the custom formatter function\n",
    "def custom_xaxis_formatter(x, pos):\n",
    "    if x == 0.1:\n",
    "        return '1.4'\n",
    "    elif x == 1:\n",
    "        return '14'\n",
    "    elif x == 0.01:\n",
    "        return '0.14'\n",
    "    else:\n",
    "        return f'{x}'\n",
    "\n",
    "# Apply the custom formatter to the x-axis\n",
    "formatter = FuncFormatter(custom_xaxis_formatter)\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e49f3-40c9-4faf-8a35-a269b6c9b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define colors and labels for each category\n",
    "colors = ['C3', 'C8', 'C0']  # Corresponding to 2: 'Snowmelt', 1: 'Dry Pond', 0: 'Baseflow'\n",
    "labels = {0: 'Baseflow',1: 'Dry Pond', 2: 'Snowmelt' }\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3]  # Set boundaries for each category\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = plt.scatter(parameters['ET'], all_dw_f_sum, c=parameters['period'], cmap=cmap, norm=norm)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$\\log(Q_z^f) \\ [m^3/s]$')\n",
    "\n",
    "# Create a color bar with appropriate labels for the periods\n",
    "cbar = plt.colorbar(scatter, ticks=[0.5, 1.5, 2.5])  # Position the ticks between boundaries\n",
    "cbar.ax.set_yticklabels([labels[0], labels[1], labels[2]])  # Apply labels\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de865c05-0393-463a-b182-37bc72938205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define colors and labels for each category\n",
    "colors = ['C3', 'C8', 'C0']  # Corresponding to 2: 'Snowmelt', 1: 'Dry Pond', 0: 'Baseflow'\n",
    "labels = {0: 'Baseflow',1: 'Dry Pond', 2: 'Snowmelt' }\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3]  # Set boundaries for each category\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = plt.scatter(parameters['ET'][parameters['period']!=1], all_dw_f_sum[parameters['period']!=1], c=parameters['period'][parameters['period']!=1], cmap=cmap, norm=norm)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$\\log(Q_z^f) \\ [m^3/s]$')\n",
    "\n",
    "# Create a color bar with appropriate labels for the periods\n",
    "cbar = plt.colorbar(scatter, ticks=[0.5, 1.5, 2.5])  # Position the ticks between boundaries\n",
    "cbar.ax.set_yticklabels([labels[0], labels[1], labels[2]])  # Apply labels\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ae437-3b5d-4cdf-a354-ef689a6ec157",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameters['ET'],all_dw_f_sum, c= parameters['period']) # 2=C0, 1=C8, 0=C3\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$log(Q_z^f) [m3/s]$')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209126d0-49d8-442d-a0c0-aab2cb637848",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameters['ET'],all_dw_f_sum*86400, c= parameters['period'])\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$log(Q_z^f) [m3/s]$')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855aa90a-6314-4543-a788-e609b3897d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b0798-2b10-4869-9cb0-a29505b71c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pond_floodplain = ((pond+downstream+upstream)==2)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46466bf-e8e4-41a4-9ab9-c7c268a7c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_dw_f[0,:,:]-0.005*pond_floodplain,vmin = -0.01,vmax = 0.01,cmap = 'RdBu') #np.where(parameters['period']==0)[0][0],:,:],\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4793cc-d5b0-4a81-911f-b10c619a7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "pond = np.load('../data/characterization_data/Beaver_pond_dam/pond_baseflow.npy')\n",
    "pond_sm = np.load('../data/characterization_data/Beaver_pond_dam/pond_snowmelt.npy')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808bf01-187a-4d18-bc92-a66332426d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pond_floodplain = ((pond+downstream+upstream)==2)*1\n",
    "pond_floodplain_sm = ((pond_sm+downstream+upstream)==2)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76771e4d-b647-4cb3-9a9c-1eed178080c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ET = np.zeros(500)\n",
    "for i in range(500):\n",
    "    if parameters['period'][i]==0:\n",
    "        correction_ET[i] = np.sum(parameters['ET'][i]*pond_floodplain)/86400\n",
    "    elif parameters['period'][i]==2:\n",
    "        correction_ET[i] = np.sum(parameters['ET'][i]*pond_floodplain_sm)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61fb08-0f8d-4d63-a6ba-17fafb9939af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_corrected = np.zeros(all_dw_f.shape)\n",
    "for i in range(500):\n",
    "    if parameters['period'][i]==0:\n",
    "        all_dw_f_corrected[i,:,:] = all_dw_f[i,:,:]-parameters['ET'][i]*pond_floodplain\n",
    "    elif parameters['period'][i]==2:\n",
    "        all_dw_f_corrected[i,:,:] = all_dw_f[i,:,:]-parameters['ET'][i]*pond_floodplain_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61981c8-30d3-479c-a352-8880c386b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_corrected_sum = np.sum((all_dw_f_corrected*(all_dw_f_corrected>0)).reshape(num_MC,-1),axis = 1)/spd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b734b1b-ff38-425b-b723-86fdbe992a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'corrected_Qzf': all_dw_f_corrected_sum,\n",
    "    'Qzf': all_dw_f_sum\n",
    "}\n",
    "\n",
    "# Convert the arrays to a DataFrame\n",
    "arrays_df = pd.DataFrame(data)\n",
    "\n",
    "# Concatenate the DataFrame with parameters, ensuring correct alignment\n",
    "combined_df = pd.concat([arrays_df, parameters], axis=1)\n",
    "df =combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12295472-e75d-4486-96f6-31949ae1c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b78271-dbbd-4f2f-9e28-621a541d092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1_Qzf = df[(df['period'] == 1) & (df['success'] == 1)]['Qzf']\n",
    "df_0_1_Qzf = df[(df['period'] == 0) & (df['success'] == 1)]['Qzf']\n",
    "df_0_1_corrected_Qzf = df[(df['period'] == 0) & (df['success'] == 1)]['corrected_Qzf']\n",
    "df_2_1_Qzf = df[(df['period'] == 2) & (df['success'] == 1)]['Qzf']\n",
    "df_2_1_corrected_Qzf = df[(df['period'] == 2) & (df['success'] == 1)]['corrected_Qzf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72324690-54cc-4938-a154-fae4416dd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data into a list for the boxplot\n",
    "data_to_plot = [df_1_1_Qzf, df_0_1_Qzf, df_0_1_corrected_Qzf, df_2_1_Qzf, df_2_1_corrected_Qzf]\n",
    "\n",
    "# Create boxplots based on the conditions\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# Create boxplot\n",
    "ax.boxplot(data_to_plot, labels=[\n",
    "    'Qzf (Period 1, Success 1)', \n",
    "    'Qzf (Period 0, Success 1)', \n",
    "    'Corrected Qzf (Period 0, Success 1)', \n",
    "    'Qzf (Period 2, Success 1)', \n",
    "    'Corrected Qzf (Period 2, Success 1)'\n",
    "])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Boxplots for Qzf and Corrected Qzf by Period and Success')\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c7fcc6-5f5e-4f74-93ac-8970e0199b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fit linear lines for each period and plot them\n",
    "# For Baseflow (period = 0)\n",
    "baseflow_x = df[(df['period'] == 0) & (df['success'] == 1)]['ET']\n",
    "baseflow_y = df[(df['period'] == 0) & (df['success'] == 1)]['corrected_Qzf']\n",
    "baseflow_fit = np.polyfit(baseflow_x, np.log(baseflow_y), 1)  # Log scale fit\n",
    "plt.plot(baseflow_x, np.exp(np.polyval(baseflow_fit, baseflow_x)), 'C3',linestyle = '--', label='Baseflow fit')\n",
    "\n",
    "\n",
    "baseflow_x = df[(df['period'] == 0) & (df['success'] == 1)]['ET']\n",
    "baseflow_y = df[(df['period'] == 0) & (df['success'] == 1)]['Qzf']\n",
    "baseflow_fit = np.polyfit(baseflow_x, np.log(baseflow_y), 1)  # Log scale fit\n",
    "plt.plot(baseflow_x, np.exp(np.polyval(baseflow_fit, baseflow_x)), 'C3', label='Baseflow fit')\n",
    "\n",
    "\n",
    "# For Dry Pond (period = 1)\n",
    "dry_pond_x = df[(df['period'] == 1) & (df['success'] == 1)]['ET']\n",
    "dry_pond_y = df[(df['period'] == 1) & (df['success'] == 1)]['Qzf']\n",
    "dry_pond_fit = np.polyfit(dry_pond_x, np.log(dry_pond_y), 1)  # Log scale fit\n",
    "plt.plot(dry_pond_x, np.exp(np.polyval(dry_pond_fit, dry_pond_x)), 'C8', label='Dry Pond fit')\n",
    "\n",
    "\n",
    "# For Snowmelt (period = 2)\n",
    "snowmelt_x = df[(df['period'] == 2) & (df['success'] == 1)]['ET']\n",
    "snowmelt_y = df[(df['period'] == 2) & (df['success'] == 1)]['Qzf']\n",
    "snowmelt_fit = np.polyfit(snowmelt_x, np.log(snowmelt_y), 1)  # Log scale fit\n",
    "plt.plot(snowmelt_x, np.exp(np.polyval(snowmelt_fit, snowmelt_x)), 'C0', label='Snowmelt fit')\n",
    "\n",
    "\n",
    "# For Snowmelt (period = 2)\n",
    "snowmelt_x = df[(df['period'] == 2) & (df['success'] == 1)]['ET']\n",
    "snowmelt_y = df[(df['period'] == 2) & (df['success'] == 1)]['corrected_Qzf']\n",
    "snowmelt_fit = np.polyfit(snowmelt_x, np.log(snowmelt_y), 1)  # Log scale fit\n",
    "plt.plot(snowmelt_x, np.exp(np.polyval(snowmelt_fit, snowmelt_x)), 'C0',linestyle = '--', label='Snowmelt fit')\n",
    "\n",
    "# Scatter plots (with fitted lines)\n",
    "#plt.scatter(baseflow_x, baseflow_y, edgecolors='C3', c='C3', marker='^', label='Baseflow')\n",
    "#plt.scatter(dry_pond_x, dry_pond_y, edgecolors='C8', c='C8', marker='o', label='Dry Pond')\n",
    "#plt.scatter(snowmelt_x, snowmelt_y, edgecolors='C0', c='C0', marker='s', label='Snowmelt')\n",
    "\n",
    "# Adding labels and color bar as before\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$\\log(Q_z^f) \\ [m^3/s]$')\n",
    "\n",
    "# Re-add color bar for the scatter plot\n",
    "cbar = plt.colorbar(scatter, ticks=[0.5, 1.5, 2.5])\n",
    "cbar.ax.set_yticklabels([labels[0], labels[1], labels[2]])\n",
    "\n",
    "# Show the plot with legends for the lines\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481cb3b-78f2-46b0-b57a-43748c7baf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define colors and labels for each category\n",
    "colors = ['C3', 'C8', 'C0']  # Corresponding to 2: 'Snowmelt', 1: 'Dry Pond', 0: 'Baseflow'\n",
    "labels = {0: 'Baseflow',1: 'Dry Pond', 2: 'Snowmelt' }\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3]  # Set boundaries for each category\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = plt.scatter(parameters['ET'][(parameters['success']==1)&(parameters['period']==1)], all_dw_f_sum[(parameters['success']==1)&(parameters['period']==1)], c = parameters['period'][(parameters['success']==1)&(parameters['period']==1)], cmap=cmap, norm=norm)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$\\log(Q_z^f) \\ [m^3/s]$')\n",
    "\n",
    "plt.scatter(df[(df['period'] == 2) & (df['success'] == 1) & (df['zf_change'] >0.2)]['ET'],df[(df['period'] == 2) & (df['success'] == 1) & (df['zf_change'] >0.2)]['corrected_Qzf'],marker = '^',c='C0')\n",
    "plt.scatter(df[(df['period'] == 0) & (df['success'] == 1) & (df['zf_change'] >0.2)]['ET'],df[(df['period'] == 0) & (df['success'] == 1) & (df['zf_change'] >0.2)]['corrected_Qzf'],marker = '^',c='C3')\n",
    "\n",
    "# Create a color bar with appropriate labels for the periods\n",
    "cbar = plt.colorbar(scatter, ticks=[0.5, 1.5, 2.5])  # Position the ticks between boundaries\n",
    "cbar.ax.set_yticklabels([labels[0], labels[1], labels[2]])  # Apply labels\n",
    "\n",
    "#plt.plot(df[(df['period'] == 1) & (df['success'] == 1)]['ET'],df[(df['period'] == 1) & (df['success'] == 1)]['Qzf'],'.')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8e390-18d2-4628-92e0-d9d8b7610897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define colors and labels for each category\n",
    "colors = ['C3', 'C8', 'C0']  # Corresponding to 2: 'Snowmelt', 1: 'Dry Pond', 0: 'Baseflow'\n",
    "labels = {0: 'Baseflow',1: 'Dry Pond', 2: 'Snowmelt' }\n",
    "cmap = ListedColormap(colors)\n",
    "bounds = [0, 1, 2, 3]  # Set boundaries for each category\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = plt.scatter(parameters['ET'][(parameters['success']==1)&(parameters['period']>-1)], all_dw_f_sum[(parameters['success']==1)&(parameters['period']>-1)], c = parameters['period'][(parameters['success']==1)&(parameters['period']>-1)], cmap=cmap, norm=norm)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('ET [m/d]')\n",
    "plt.ylabel('$\\log(Q_z^f) \\ [m^3/s]$')\n",
    "\n",
    "plt.scatter(df[(df['period'] == 2) & (df['success'] == 1) ]['ET'],df[(df['period'] == 2) & (df['success'] == 1)]['Qzf'],c =  'C0',label = 'MC Set 3')\n",
    "\n",
    "plt.scatter(df[(df['period'] == 2) & (df['success'] == 1) ]['ET'],df[(df['period'] == 2) & (df['success'] == 1)]['corrected_Qzf'],edgecolors='C0',c = 'white',label = 'ET_Corrected \\nMC Set3')\n",
    "plt.scatter(df[(df['period'] == 0) & (df['success'] == 1) ]['ET'],df[(df['period'] == 0) & (df['success'] == 1) ]['corrected_Qzf'],edgecolors='C3',c = 'white')\n",
    "\n",
    "plt.legend()\n",
    "# Create a color bar with appropriate labels for the periods\n",
    "cbar = plt.colorbar(scatter, ticks=[0.5, 1.5, 2.5])  # Position the ticks between boundaries\n",
    "cbar.ax.set_yticklabels([labels[0], labels[1], labels[2]])  # Apply labels\n",
    "\n",
    "#plt.plot(df[(df['period'] == 1) & (df['success'] == 1)]['ET'],df[(df['period'] == 1) & (df['success'] == 1)]['Qzf'],'.')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('ET Corrected $Q_z^f$')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b939a-4134-4aff-b7cb-fe77eff17608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zf_change'] = (df['Qzf']-df['corrected_Qzf'])/df['Qzf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8ca96-8b97-4c2e-b669-2ea34c1869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(df[(df['period'] == 2) & (df['success'] == 1)]['hk_soil']*df[(df['period'] == 2) & (df['success'] == 1)]['vka_ratio_soil'],\n",
    "            df[(df['period'] == 2) & (df['success'] == 1)]['structure_ratio1']*2,c = np.log10(df[(df['period'] == 2) & (df['success'] == 1)]['corrected_Qzf']),vmin = -6,vmax= -2,cmap = 'RdBu')\n",
    "plt.xlabel('$log(K_v^{soil})$')\n",
    "plt.ylabel('Soil thickness (m)')\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# Adding color bar with title\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('$\\log($ET-corrected $ Q_z^f)$')\n",
    "\n",
    "plt.title('Simulations for Snowmelt Period from MC Set 3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac04ff2-f114-4254-9ea8-5a5bfc6d88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[(df['period'] == 0) & (df['success'] == 1)]['hk_soil']*df[(df['period'] == 0) & (df['success'] == 1)]['vka_ratio_soil'],\n",
    "            df[(df['period'] == 0) & (df['success'] == 1)]['structure_ratio1'],c = np.log10(df[(df['period'] == 0) & (df['success'] == 1)]['corrected_Qzf']),vmin = -7,vmax= -2)\n",
    "\n",
    "#plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81267c8-c068-487b-b290-618cb08efb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['period'] == 2) & (df['success'] == 1) & (df['corrected_Qzf'] <1e-4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8052b70-f649-443d-812c-d6f84db92df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['period'] == 2) & (df['success'] == 1) & (df['corrected_Qzf'] >1e-4) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c163e-caae-4eab-a5b5-ab6ec43eb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_dw_f_corrected_sum[parameters['success']==1]/all_dw_f_sum[parameters['success']==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7eb1a7-9465-450b-a0d6-d008085b54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_corrected_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4019d7e-7f63-4c55-b869-251dec0bf51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pond_floodplain*ET)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f2d1a-67a7-4ca5-9b74-e0e183a1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pond_floodplain_sm*ET)/86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae3298-e72e-45f8-93cc-07816e84f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_sum[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc2c2d-78e0-4fb1-96ba-0b6c60d56f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ET[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7465c-dfac-47ae-ab33-5b93475a4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.iloc[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edebb9f-ecd7-4b09-a6f4-55f6411a7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ET[parameters['success']==0] = 0\n",
    "all_dw_f_sum[parameters['success']==0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa09d7-46fa-4850-a1e6-4913e66c16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax((correction_ET/all_dw_f_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a4fb96-0bec-45d1-9d8c-a38a66070b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_sum[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c482d04-8461-4099-96fa-617a5795d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ET[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2833f3-0ccc-4b57-9c48-a336e7e03cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(all_dw_f[382,:,:],vmin = -0.01,vmax = 0.01,cmap = 'RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f5e5e-410e-4974-83ed-17bdc810f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.iloc[382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bdf58-78ed-4064-93e2-666cd849d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f_sum[320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93df4d-7e8e-4a47-a730-d8c9892e8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_ET[320]/all_dw_f_sum[320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281abb9-01c2-4826-b6aa-6c1d65d758dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((all_dw_f[0,:,:]-parameters['ET'][0]*pond_floodplain)[(all_dw_f[0,:,:]-0.005*pond_floodplain)>0])/(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1dd44f-bede-44c8-9485-e517254bd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dw_f[periods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9ed9b-5081-4975-ae99-57275672315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(all_dw_f[parameters['period']==0,:,:],axis = 0)>0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f4643-b9d4-4972-81f1-25bcf749f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(parameters['ET'],parameters['precip'],c = np.log10(all_dw_f_sum))\n",
    "#plt.yscale('log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559cbd84-1ae1-4033-a663-4ff662a6f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Assuming `parameters`, `all_dw_f_sum`, and `all_h_flux_f_sum` are already defined\n",
    "\n",
    "# Filter out period == 1\n",
    "filtered_parameters = parameters[parameters['period'] != 1]\n",
    "structure_ratio2 = filtered_parameters['structure_ratio2']\n",
    "hk_soil = filtered_parameters['hk_soil']\n",
    "vka_ratio_soil = filtered_parameters['vka_ratio_soil']\n",
    "hk_gravel = filtered_parameters['hk_gravel']\n",
    "\n",
    "# Calculate the color array\n",
    "color = np.log10(hk_soil * vka_ratio_soil / hk_gravel)\n",
    "\n",
    "# Calculate the y values for the scatter plot\n",
    "y_values = (all_dw_f_sum / all_h_flux_f_sum)[parameters['period'] != 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(structure_ratio2, y_values, c=color)\n",
    "plt.colorbar(label='$\\log(K_{v}^{soil}/K_{h}^{gravel})$')\n",
    "plt.xlim(0.01,3)\n",
    "plt.yscale('log') \n",
    "plt.xscale('log') \n",
    "plt.xlabel('Gravel Thickness (m)')\n",
    "plt.ylabel('$\\log(Q_z^f/Q_x^f)$')\n",
    "\n",
    "# Define the custom formatter function\n",
    "def custom_xaxis_formatter(x, pos):\n",
    "    if x == 0.1:\n",
    "        return '1.4'\n",
    "    elif x == 1:\n",
    "        return '14'\n",
    "    elif x == 0.01:\n",
    "        return '0.14'\n",
    "    else:\n",
    "        return f'{x}'\n",
    "\n",
    "# Apply the custom formatter to the x-axis\n",
    "formatter = FuncFormatter(custom_xaxis_formatter)\n",
    "plt.gca().xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52299f21-c175-4f3f-b772-d239855b22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_matrix = np.zeros((len(xlabel), nrow, ncol))\n",
    "for i in range(nrow):\n",
    "    print(i)\n",
    "    for j in range(ncol):\n",
    "        if (upstream+downstream)[i,j]!=0:\n",
    "            criterion = (parameters['period']=='baseflow') & (parameters['success']==1)\n",
    "            max_attempts = 10\n",
    "            attempts = 0\n",
    "            success = False\n",
    "            while attempts < max_attempts and not success:\n",
    "                try:\n",
    "                    dgsa_measures = DGSA_light(log_paras.values[criterion,:], \n",
    "                                       all_dw_f[criterion,i,j].reshape(-1,1),\n",
    "                                       xlabel,n_clsters=3,n_boots=3000)\n",
    "                    success = True\n",
    "                except ValueError as e:\n",
    "                    attempts += 1\n",
    "                    print(f\"Attempt {attempts} failed: {e}\")\n",
    "            SA_matrix[:,i,j] = dgsa_measures[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003b279-858f-4550-bd88-7c25a666327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('SA_baseflow.npy',SA_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664a9de-d1b0-465e-891b-b406f58b49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgsa_measures[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d8f7d-1225-466e-90c8-eebacbfb3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ET_SA_baseflow = \n",
    "plt.imshow(upstream+downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64b8b7-cfa1-42ff-8882-167ff26cc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_SA_baseflow = \n",
    "plt.imshow(upstream+downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29353264-ca9a-4dcc-a2d3-e843cb7c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_soil_SA_baseflow = \n",
    "plt.imshow(upstream+downstream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
